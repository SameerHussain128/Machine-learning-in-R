# Load necessary libraries
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(summarytools)
library(caret)
# Step 1: Loading the Data
data <- read.csv("D:/Data Science 6pm/ML in R/Salary prediction project in R/Data.csv")
# Step 2: Exploring and Understanding the Data
# Display the structure of the dataset
str(data)
# Display summary statistics
summary(data)
# Display the first few rows of the dataset
head(data)
# Display more detailed summary statistics
print(dfSummary(data), method = 'render')
# Step 3: Data Cleaning
# Check for missing values
missing_values <- sapply(data, function(x) sum(is.na(x)))
data <- data %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))
print(data)
data = factor(data,
levels = c('France','Spain','Germany'),
labels = c(1,2,3))
# Check the encoded data
print(data)
data$Country = factor(data$Country ,
levels = c('France','Spain','Germany'),
labels = c(1,2,3))
data$Country = factor(data$Country,
levels = c('France','Spain','Germany'),
labels = c(1,2,3))
# Define a mapping for countries to numeric codes
data = factor(data$Country,
levels = c('France','Spain','Germany'),
labels = c(1,2,3))
data = factor(data,
levels = c('France','Spain','Germany'),
labels = c(1,2,3))
# Check the encoded data
print(data)
data = factor(data,
levels = c('France','Spain','Germany'),
labels = c(1,2,3))
data = factor(data,
levels = c('No','Yes'),
labels = c(0,1))
# Check the encoded data
print(data)
# Split data into 70% training and 30% testing
train_index <- createDataPartition(data$country, p = 0.7, list = FALSE)
library(tidyverse)
library(DMwR)
# Load the dataset
data <- read.csv('D:/Data Science 6pm/ML in R/Data.csv')
# Initial exploration
head(data)
summary(data)
str(data)
colnames(data)  # View column names to identify the target variable
# Data Preprocessing
colSums(is.na(data))
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
